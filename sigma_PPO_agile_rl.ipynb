{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pjlwOougzhuJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import trange\n",
    "from agilerl.hpo.mutation import Mutations\n",
    "from agilerl.hpo.tournament import TournamentSelection\n",
    "from agilerl.utils.utils import create_population, make_vect_envs\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yXqxF_wPZOr4"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxVV3QfVyunP",
    "outputId": "cf0242d3-5a9a-4acb-8aa8-07ab2842f13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", device)\n",
    "NET_CONFIG = {\n",
    "    \"arch\": \"mlp\",  # Network architecture\n",
    "    \"hidden_size\": [32, 32],  # Actor hidden size\n",
    "}\n",
    "\n",
    "INIT_HP = {\n",
    "    \"POP_SIZE\": 6,  # Population size\n",
    "    \"DISCRETE_ACTIONS\": False,  # Discrete action space\n",
    "    \"BATCH_SIZE\": 128,  # Batch size\n",
    "    \"LR\": 1e-3,  # Learning rate\n",
    "    \"LEARN_STEP\": 128,  # Learning frequency\n",
    "    \"GAMMA\": 0.99,  # Discount factor\n",
    "    \"GAE_LAMBDA\": 0.95,  # Lambda for general advantage estimation\n",
    "    \"ACTION_STD_INIT\": 0.6,  # Initial action standard deviation\n",
    "    \"CLIP_COEF\": 0.2,  # Surrogate clipping coefficient\n",
    "    \"ENT_COEF\": 0.01,  # Entropy coefficient\n",
    "    \"VF_COEF\": 0.5,  # Value function coefficient\n",
    "    \"MAX_GRAD_NORM\": 0.5,  # Maximum norm for gradient clipping\n",
    "    \"TARGET_KL\": None,  # Target KL divergence threshold\n",
    "    \"UPDATE_EPOCHS\": 4,  # Number of policy update epochs\n",
    "    # Swap image channels dimension from last to first [H, W, C] -> [C, H, W]\n",
    "     \"wandb_api_key\":'XYZ',\n",
    "    \"WANDB\": True,\n",
    "    \"CHANNELS_LAST\": False,\n",
    "}\n",
    "\n",
    "num_envs = 2\n",
    "env_name=\"Pendulum-v1\"\n",
    "env = make_vect_envs(env_name, num_envs=num_envs)  # Create environment\n",
    "\n",
    "# env = gym.vector.AsyncVectorEnv(\n",
    "#         [lambda: Simple2DEnv() for i in range(num_envs)]\n",
    "#     )\n",
    "\n",
    "try:\n",
    "    state_dim = env.single_observation_space.n  # Discrete observation space\n",
    "    one_hot = True  # Requires one-hot encoding\n",
    "except Exception:\n",
    "    state_dim = env.single_observation_space.shape  # Continuous observation space\n",
    "    one_hot = False  # Does not require one-hot encoding\n",
    "try:\n",
    "    action_dim = env.single_action_space.n  # Discrete action space\n",
    "except Exception:\n",
    "    action_dim = env.single_action_space.shape[0]  # Continuous action space\n",
    "\n",
    "if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "    state_dim = (state_dim[2], state_dim[0], state_dim[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WYX0YITh9X3q"
   },
   "outputs": [],
   "source": [
    "tournament = TournamentSelection(\n",
    "    tournament_size=2,  # Tournament selection size\n",
    "    elitism=True,  # Elitism in tournament selection\n",
    "    population_size=INIT_HP[\"POP_SIZE\"],  # Population size\n",
    "    eval_loop=1,  # Evaluate using last N fitness scores\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "max_steps = 200000  # Max steps\n",
    "evo_steps = 10000  # Evolution frequency\n",
    "eval_steps = None  # Evaluation steps per episode - go until done\n",
    "eval_loop = 1  # Number of evaluation episodes\n",
    "\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pQf2-ZxFXDVv"
   },
   "outputs": [],
   "source": [
    "class MyMutations(Mutations):\n",
    "    def reinit_opt(self, individual):\n",
    "        if self.multi_agent:\n",
    "            # Reinitialise optimizer\n",
    "            raise NotImplementedError(\n",
    "                    f\"Mutations is not implemented for {individual.algo}\"\n",
    "                )\n",
    "            actor_opts = getattr(individual, self.algo[\"actor\"][\"optimizer\"])\n",
    "\n",
    "            net_params = [\n",
    "                actor.parameters()\n",
    "                for actor in getattr(individual, self.algo[\"actor\"][\"eval\"])\n",
    "            ]\n",
    "\n",
    "            offspring_actor_opts = [\n",
    "                type(actor_opt)(net_param, lr=individual.lr_actor)\n",
    "                for actor_opt, net_param in zip(actor_opts, net_params)\n",
    "            ]\n",
    "\n",
    "            setattr(\n",
    "                individual,\n",
    "                self.algo[\"actor\"][\"optimizer\"],\n",
    "                offspring_actor_opts,\n",
    "            )\n",
    "\n",
    "            for critic_list in self.algo[\"critics\"]:\n",
    "                critic_opts = getattr(individual, critic_list[\"optimizer\"])\n",
    "\n",
    "                net_params = [\n",
    "                    critic.parameters()\n",
    "                    for critic in getattr(individual, critic_list[\"eval\"])\n",
    "                ]\n",
    "\n",
    "                offspring_critic_opts = [\n",
    "                    type(critic_opt)(net_param, lr=individual.lr_critic)\n",
    "                    for critic_opt, net_param in zip(critic_opts, net_params)\n",
    "                ]\n",
    "\n",
    "                setattr(\n",
    "                    individual,\n",
    "                    critic_list[\"optimizer\"],\n",
    "                    offspring_critic_opts,\n",
    "                )\n",
    "        else:\n",
    "            if individual.algo in [\"PPO\"]:\n",
    "                print(\"Mutations is here\")\n",
    "                # Reinitialise optimizer\n",
    "                opt = getattr(individual, self.algo[\"actor\"][\"optimizer\"])\n",
    "                actor_net_params = getattr(\n",
    "                    individual, self.algo[\"actor\"][\"eval\"]\n",
    "                ).parameters()\n",
    "                critic_net_params = getattr(\n",
    "                    individual, self.algo[\"critics\"][0][\"eval\"]\n",
    "                ).parameters()\n",
    "                vol_net_params = getattr(\n",
    "                    individual, self.algo[\"critics\"][1][\"eval\"]\n",
    "                ).parameters()\n",
    "                opt_args = [\n",
    "                    {\"params\": actor_net_params, \"lr\": individual.lr},\n",
    "                    {\"params\": critic_net_params, \"lr\": individual.lr},\n",
    "                    {\"params\": vol_net_params, \"lr\": individual.lr},\n",
    "                ]\n",
    "                setattr(\n",
    "                    individual,\n",
    "                    self.algo[\"actor\"][\"optimizer\"],\n",
    "                    type(opt)(opt_args),\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    f\"Mutations 2 is not implemented for {individual.algo}\"\n",
    "                )\n",
    "                # Reinitialise optimizer\n",
    "                actor_opt = getattr(individual, self.algo[\"actor\"][\"optimizer\"])\n",
    "                net_params = getattr(\n",
    "                    individual, self.algo[\"actor\"][\"eval\"]\n",
    "                ).parameters()\n",
    "                if individual.algo in [\"DDPG\", \"TD3\"]:\n",
    "                    setattr(\n",
    "                        individual,\n",
    "                        self.algo[\"actor\"][\"optimizer\"],\n",
    "                        type(actor_opt)(net_params, lr=individual.lr_actor),\n",
    "                    )\n",
    "                else:\n",
    "                    setattr(\n",
    "                        individual,\n",
    "                        self.algo[\"actor\"][\"optimizer\"],\n",
    "                        type(actor_opt)(net_params, lr=individual.lr),\n",
    "                    )\n",
    "\n",
    "                # If algorithm has critics, reinitialise their optimizers too\n",
    "                for critic in self.algo[\"critics\"]:\n",
    "                    critic_opt = getattr(individual, critic[\"optimizer\"])\n",
    "                    net_params = getattr(individual, critic[\"eval\"]).parameters()\n",
    "                    setattr(\n",
    "                        individual,\n",
    "                        critic[\"optimizer\"],\n",
    "                        type(critic_opt)(net_params, lr=individual.lr_critic),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6y30OuDcAB7A"
   },
   "outputs": [],
   "source": [
    "nets = {\n",
    "       \"actor\": {\"eval\": \"actor\", \"optimizer\": \"optimizer\"},\n",
    "       \"critics\": [\n",
    "             {\"eval\": \"critic\", \"optimizer\": \"critic_optimizer\"},\n",
    "             {\"eval\": \"actor_var\", \"optimizer\": \"actor_var_optimizer\"}\n",
    "       ]\n",
    "}\n",
    "\n",
    "mutations = MyMutations(\n",
    "    algo=\"PPO\",  # Algorithm\n",
    "    no_mutation=0.4,  # No mutation\n",
    "    architecture=0.2,  # Architecture mutation\n",
    "    new_layer_prob=0.2,  # New layer mutation\n",
    "    parameters=0.2,  # Network parameters mutation\n",
    "    activation=0,  # Activation layer mutation\n",
    "    rl_hp=0.2,  # Learning HP mutation\n",
    "    rl_hp_selection=[\"lr\", \"batch_size\", \"learn_step\"],  # RL HPs to choose from\n",
    "    mutation_sd=0.1,  # Mutation strength\n",
    "    arch=NET_CONFIG[\"arch\"],  # Network architecture\n",
    "    rand_seed=1,  # Random seed\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "mutations.algo = mutations.algo | nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArwYs6lDaZ4r"
   },
   "source": [
    "### Custom Actor and Volatility Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eJ7asTzWBntP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Vs1yEEo7BtLi"
   },
   "outputs": [],
   "source": [
    "class MLPActor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLPActor, self).__init__()\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(input_size, 64)\n",
    "        self.linear_layer_2 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.linear_layer_1(x))\n",
    "        x1 = self.linear_layer_2(x1)\n",
    "\n",
    "        return x1\n",
    "\n",
    "actor = MLPActor(state_dim[0], action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RWZRLRQ73KhQ"
   },
   "outputs": [],
   "source": [
    "class VolatilityNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(VolatilityNet, self).__init__()\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(input_size, 64)\n",
    "        self.linear_layer_2 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.linear_layer_1(x))\n",
    "        x1 = self.relu2(self.linear_layer_2(x1))\n",
    "\n",
    "        return x1\n",
    "\n",
    "\n",
    "vol_net = VolatilityNet(state_dim[0], action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "P7pVhfa261uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fDs7uTRvCiTi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DvO-h30GA_cI"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from agilerl.networks.custom_components import GumbelSoftmax, NoisyLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WJDdY19d3OPv"
   },
   "outputs": [],
   "source": [
    "from agilerl.wrappers.make_evolvable import MakeEvolvable\n",
    "\n",
    "\n",
    "\n",
    "evolvable_actor = MakeEvolvable(actor,\n",
    "                                input_tensor=torch.randn(state_dim[0]),\n",
    "                                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2FOjTrnnCY5u"
   },
   "outputs": [],
   "source": [
    "evolvable_vol_net = MakeEvolvable(vol_net,\n",
    "                                input_tensor=torch.randn(state_dim[0]),\n",
    "                                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8EpjoUoCd2O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU-cKOwwaUtk"
   },
   "source": [
    "Quick Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DKZj0hutHjMJ"
   },
   "outputs": [],
   "source": [
    "state, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHhW49uX7-7u",
    "outputId": "60d8a613-8f14-4ae1-8466-89d441555f31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3404],\n",
       "        [0.0314]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "vol_net(torch.tensor(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y30O0Nvz8Va1",
    "outputId": "398ebd79-2def-4857-9b49-22b24a65c340"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0195],\n",
       "        [0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evolvable_vol_net.forward(torch.tensor(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOSKhC38FyRb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3m0aF1T8aVK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xCZSStPaW5L"
   },
   "source": [
    "### Custom Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_blx6LRu4jkU"
   },
   "outputs": [],
   "source": [
    "class MLPCritic(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLPCritic, self).__init__()\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(input_size, 64)\n",
    "        self.linear_layer_2 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear_layer_1(x))\n",
    "        x = self.linear_layer_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vgmXSxb_4qSm"
   },
   "outputs": [],
   "source": [
    "critic = MLPCritic(state_dim[0], 1)\n",
    "evolvable_critic = MakeEvolvable(critic,\n",
    "                                input_tensor=torch.randn(state_dim[0]),\n",
    "                                device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K1aRurPaPZM"
   },
   "source": [
    "### Custom PPO Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "m33UzYOr56kU"
   },
   "outputs": [],
   "source": [
    "from agilerl.algorithms.ppo import PPO\n",
    "from torch.distributions import Categorical, MultivariateNormal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SBej1tQJF1l9"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import inspect\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical, MultivariateNormal\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from agilerl.networks.evolvable_cnn import EvolvableCNN\n",
    "from agilerl.networks.evolvable_mlp import EvolvableMLP\n",
    "from agilerl.utils.algo_utils import chkpt_attribute_to_device, unwrap_optimizer\n",
    "from agilerl.wrappers.make_evolvable import MakeEvolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HWZMKCSnDdH6"
   },
   "outputs": [],
   "source": [
    "class SigmaPPO(PPO):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        one_hot,\n",
    "        discrete_actions,\n",
    "        max_action=1,\n",
    "        min_action=-1,\n",
    "        index=0,\n",
    "        net_config={\"arch\": \"mlp\", \"hidden_size\": [64, 64]},\n",
    "        batch_size=64,\n",
    "        lr=1e-4,\n",
    "        learn_step=2048,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        mut=None,\n",
    "        action_std_init=0.6,\n",
    "        clip_coef=0.2,\n",
    "        ent_coef=0.01,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        target_kl=None,\n",
    "        update_epochs=4,\n",
    "        actor_network=None,\n",
    "        critic_network=None,\n",
    "        device=\"cpu\",\n",
    "        accelerator=None,\n",
    "        wrap=True,\n",
    "    ):\n",
    "        assert isinstance(\n",
    "            state_dim, (list, tuple)\n",
    "        ), \"State dimension must be a list or tuple.\"\n",
    "        assert isinstance(\n",
    "            action_dim, (int, np.integer)\n",
    "        ), \"Action dimension must be an integer.\"\n",
    "        assert isinstance(\n",
    "            one_hot, bool\n",
    "        ), \"One-hot encoding flag must be boolean value True or False.\"\n",
    "        assert isinstance(\n",
    "            discrete_actions, bool\n",
    "        ), \"Discrete actions flag must be boolean value True or False.\"\n",
    "        assert isinstance(\n",
    "            max_action,\n",
    "            (float, int, np.float32, np.float64, np.integer, list, np.ndarray),\n",
    "        ), \"Max action must be a float or integer.\"\n",
    "        assert isinstance(\n",
    "            min_action,\n",
    "            (float, int, np.float32, np.float64, np.integer, list, np.ndarray),\n",
    "        ), \"Min action must be a float or integer.\"\n",
    "        if isinstance(min_action, list):\n",
    "            assert (\n",
    "                len(min_action) == action_dim\n",
    "            ), \"Length of min_action must be equal to action_dim.\"\n",
    "            min_action = np.array(min_action)\n",
    "        if isinstance(max_action, list):\n",
    "            assert (\n",
    "                len(max_action) == action_dim\n",
    "            ), \"Length of max_action must be equal to action_dim.\"\n",
    "            max_action = np.array(max_action)\n",
    "        if isinstance(max_action, np.ndarray) or isinstance(min_action, np.ndarray):\n",
    "            assert np.all(\n",
    "                max_action > min_action\n",
    "            ), \"Max action must be greater than min action.\"\n",
    "        else:\n",
    "            assert (\n",
    "                max_action > min_action\n",
    "            ), \"Max action must be greater than min action.\"\n",
    "        assert isinstance(index, int), \"Agent index must be an integer.\"\n",
    "        assert isinstance(batch_size, int), \"Batch size must be an integer.\"\n",
    "        assert batch_size >= 1, \"Batch size must be greater than or equal to one.\"\n",
    "        assert isinstance(lr, float), \"Learning rate must be a float.\"\n",
    "        assert lr > 0, \"Learning rate must be greater than zero.\"\n",
    "        assert isinstance(gamma, (float, int)), \"Gamma must be a float.\"\n",
    "        assert isinstance(gae_lambda, (float, int)), \"Lambda must be a float.\"\n",
    "        assert gae_lambda >= 0, \"Lambda must be greater than or equal to zero.\"\n",
    "        assert isinstance(\n",
    "            action_std_init, (float, int)\n",
    "        ), \"Action standard deviation must be a float.\"\n",
    "        assert (\n",
    "            action_std_init >= 0\n",
    "        ), \"Action standard deviation must be greater than or equal to zero.\"\n",
    "        assert isinstance(\n",
    "            clip_coef, (float, int)\n",
    "        ), \"Clipping coefficient must be a float.\"\n",
    "        assert (\n",
    "            clip_coef >= 0\n",
    "        ), \"Clipping coefficient must be greater than or equal to zero.\"\n",
    "        assert isinstance(\n",
    "            ent_coef, (float, int)\n",
    "        ), \"Entropy coefficient must be a float.\"\n",
    "        assert (\n",
    "            ent_coef >= 0\n",
    "        ), \"Entropy coefficient must be greater than or equal to zero.\"\n",
    "        assert isinstance(\n",
    "            vf_coef, (float, int)\n",
    "        ), \"Value function coefficient must be a float.\"\n",
    "        assert (\n",
    "            vf_coef >= 0\n",
    "        ), \"Value function coefficient must be greater than or equal to zero.\"\n",
    "        assert isinstance(\n",
    "            max_grad_norm, (float, int)\n",
    "        ), \"Maximum norm for gradient clipping must be a float.\"\n",
    "        assert (\n",
    "            max_grad_norm >= 0\n",
    "        ), \"Maximum norm for gradient clipping must be greater than or equal to zero.\"\n",
    "        assert (\n",
    "            isinstance(target_kl, (float, int)) or target_kl is None\n",
    "        ), \"Target KL divergence threshold must be a float.\"\n",
    "        if target_kl is not None:\n",
    "            assert (\n",
    "                target_kl >= 0\n",
    "            ), \"Target KL divergence threshold must be greater than or equal to zero.\"\n",
    "        assert isinstance(\n",
    "            update_epochs, int\n",
    "        ), \"Policy update epochs must be an integer.\"\n",
    "        assert (\n",
    "            update_epochs >= 1\n",
    "        ), \"Policy update epochs must be greater than or equal to one.\"\n",
    "        assert isinstance(\n",
    "            wrap, bool\n",
    "        ), \"Wrap models flag must be boolean value True or False.\"\n",
    "\n",
    "        self.algo = \"PPO\"\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.one_hot = one_hot\n",
    "        self.discrete_actions = discrete_actions\n",
    "        self.max_action = max_action\n",
    "        self.min_action = min_action\n",
    "        self.net_config = net_config\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.learn_step = learn_step\n",
    "        self.gamma = gamma\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.mut = mut\n",
    "        self.action_std_init = action_std_init\n",
    "        self.clip_coef = clip_coef\n",
    "        self.ent_coef = ent_coef\n",
    "        self.vf_coef = vf_coef\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.target_kl = target_kl\n",
    "        self.update_epochs = update_epochs\n",
    "        self.actor_network = actor_network\n",
    "        self.critic_network = critic_network\n",
    "        self.device = device\n",
    "        self.accelerator = accelerator\n",
    "\n",
    "        self.index = index\n",
    "        self.scores = []\n",
    "        self.fitness = []\n",
    "        self.steps = [0]\n",
    "\n",
    "\n",
    "\n",
    "        if self.actor_network is not None and self.critic_network is not None:\n",
    "\n",
    "            self.actor = actor_network\n",
    "            self.critic = critic_network[0] ## !\n",
    "            self.vol_net = critic_network[1] ## !\n",
    "\n",
    "            if isinstance(self.actor, (EvolvableMLP, EvolvableCNN)) and isinstance(\n",
    "                self.critic, (EvolvableMLP, EvolvableCNN)\n",
    "            ):\n",
    "                self.net_config = self.actor.net_config\n",
    "            elif isinstance(self.actor, MakeEvolvable) and isinstance(\n",
    "                self.critic, MakeEvolvable\n",
    "            ):\n",
    "                self.net_config = None\n",
    "            else:\n",
    "                assert (\n",
    "                    False\n",
    "                ), f\"'actor_network' argument is of type {type(actor_network)} and 'critic_network' of type {type(critic_network)}, \\\n",
    "                                both must be the same type and be of type EvolvableMLP, EvolvableCNN or MakeEvolvable\"\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(\"Both Aren't None\")\n",
    "            assert isinstance(self.net_config, dict), \"Net config must be a dictionary.\"\n",
    "            assert (\n",
    "                \"arch\" in self.net_config.keys()\n",
    "            ), \"Net config must contain arch: 'mlp' or 'cnn'.\"\n",
    "\n",
    "            # Set up network output activations\n",
    "            if \"mlp_output_activation\" not in self.net_config.keys():\n",
    "                if self.discrete_actions:\n",
    "                    self.net_config[\"mlp_output_activation\"] = \"Softmax\"\n",
    "                elif np.any(self.min_action < 0):\n",
    "                    self.net_config[\"mlp_output_activation\"] = \"Tanh\"\n",
    "                else:\n",
    "                    self.net_config[\"mlp_output_activation\"] = \"Sigmoid\"\n",
    "\n",
    "            if \"mlp_activation\" not in self.net_config.keys():\n",
    "                self.net_config[\"mlp_activation\"] = \"Tanh\"\n",
    "\n",
    "            critic_net_config = copy.deepcopy(self.net_config)\n",
    "            critic_net_config[\"mlp_output_activation\"] = (\n",
    "                None  # Critic must have no output activation\n",
    "            )\n",
    "\n",
    "            # model\n",
    "            if self.net_config[\"arch\"] == \"mlp\":  # Multi-layer Perceptron\n",
    "                assert (\n",
    "                    \"hidden_size\" in self.net_config.keys()\n",
    "                ), \"Net config must contain hidden_size: int.\"\n",
    "                assert isinstance(\n",
    "                    self.net_config[\"hidden_size\"], list\n",
    "                ), \"Net config hidden_size must be a list.\"\n",
    "                assert (\n",
    "                    len(self.net_config[\"hidden_size\"]) > 0\n",
    "                ), \"Net config hidden_size must contain at least one element.\"\n",
    "                self.actor = EvolvableMLP(\n",
    "                    num_inputs=state_dim[0],\n",
    "                    num_outputs=action_dim,\n",
    "                    device=self.device,\n",
    "                    accelerator=self.accelerator,\n",
    "                    **self.net_config,\n",
    "                )\n",
    "                self.critic = EvolvableMLP(\n",
    "                    num_inputs=state_dim[0],\n",
    "                    num_outputs=1,\n",
    "                    device=self.device,\n",
    "                    accelerator=self.accelerator,\n",
    "                    **critic_net_config,\n",
    "                )\n",
    "            elif self.net_config[\"arch\"] == \"cnn\":  # Convolutional Neural Network\n",
    "                for key in [\n",
    "                    \"channel_size\",\n",
    "                    \"kernel_size\",\n",
    "                    \"stride_size\",\n",
    "                    \"hidden_size\",\n",
    "                ]:\n",
    "                    assert (\n",
    "                        key in self.net_config.keys()\n",
    "                    ), f\"Net config must contain {key}: int.\"\n",
    "                    assert isinstance(\n",
    "                        self.net_config[key], list\n",
    "                    ), f\"Net config {key} must be a list.\"\n",
    "                    assert (\n",
    "                        len(self.net_config[key]) > 0\n",
    "                    ), f\"Net config {key} must contain at least one element.\"\n",
    "                assert (\n",
    "                    \"normalize\" in self.net_config.keys()\n",
    "                ), \"Net config must contain normalize: True or False.\"\n",
    "                assert isinstance(\n",
    "                    self.net_config[\"normalize\"], bool\n",
    "                ), \"Net config normalize must be boolean value True or False.\"\n",
    "                self.actor = EvolvableCNN(\n",
    "                    input_shape=state_dim,\n",
    "                    num_actions=action_dim,\n",
    "                    device=self.device,\n",
    "                    accelerator=self.accelerator,\n",
    "                    **self.net_config,\n",
    "                )\n",
    "                self.critic = EvolvableCNN(\n",
    "                    input_shape=state_dim,\n",
    "                    num_actions=1,\n",
    "                    device=self.device,\n",
    "                    accelerator=self.accelerator,\n",
    "                    **critic_net_config,\n",
    "                )\n",
    "\n",
    "        self.arch = (\n",
    "            self.net_config[\"arch\"] if self.net_config is not None else self.actor.arch\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(\n",
    "            [\n",
    "                {\"params\": self.actor.parameters(), \"lr\": self.lr},\n",
    "                {\"params\": self.critic.parameters(), \"lr\": self.lr},\n",
    "                {\"params\": self.vol_net.parameters(), \"lr\": self.lr}, ## !\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if self.accelerator is not None:\n",
    "            if wrap:\n",
    "                self.wrap_models()\n",
    "        else:\n",
    "            self.actor = self.actor.to(self.device)\n",
    "            self.critic = self.critic.to(self.device)\n",
    "            self.vol_net = self.vol_net.to(self.device) ## !\n",
    "\n",
    "    def get_action(self, state, action=None, grad=False, action_mask=None):\n",
    "        \"\"\"Returns the next action to take in the environment.\n",
    "\n",
    "        :param state: Environment observation, or multiple observations in a batch\n",
    "        :type state: numpy.ndarray[float]\n",
    "        :param action: Action in environment to evaluate, defaults to None\n",
    "        :type action: torch.Tensor(), optional\n",
    "        :param grad: Calculate gradients on actions, defaults to False\n",
    "        :type grad: bool, optional\n",
    "        :param action_mask: Mask of legal actions 1=legal 0=illegal, defaults to None\n",
    "        :type action_mask: numpy.ndarray, optional\n",
    "        \"\"\"\n",
    "        state = self.prepare_state(state)\n",
    "\n",
    "        # print('Yo, it`s a sigma PPO')\n",
    "\n",
    "        if not grad:\n",
    "            self.actor.eval()\n",
    "            self.critic.eval()\n",
    "            with torch.no_grad():\n",
    "\n",
    "                act_out = self.actor(state)\n",
    "                if type(act_out) == tuple:\n",
    "                    raise NotImplementedError(\"Get Action 1\")\n",
    "                    action_values, std_values = act_out\n",
    "                else:\n",
    "                    action_values = act_out\n",
    "                    std_values = self.vol_net(state) ## !\n",
    "\n",
    "                # print('action_values', action_values)\n",
    "                # print('std_values', std_values)\n",
    "                state_values = self.critic(state).squeeze(-1)\n",
    "            self.actor.train()\n",
    "            self.critic.train()\n",
    "\n",
    "        else:\n",
    "            act_out = self.actor(state)\n",
    "            if type(act_out) == tuple:\n",
    "                raise NotImplementedError(\"Get Action 2\")\n",
    "                action_values, std_values = act_out\n",
    "            else:\n",
    "                action_values = act_out\n",
    "                std_values = self.vol_net(state) ## !\n",
    "            state_values = self.critic(state).squeeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "        if self.discrete_actions:\n",
    "            # print('Discrete')\n",
    "            if action_mask is not None:\n",
    "                action_mask = torch.from_numpy(action_mask)\n",
    "                action_values *= action_mask\n",
    "\n",
    "            dist = Categorical(action_values)\n",
    "        else:\n",
    "            # print(\"self.action_var\", self.action_var)\n",
    "            # cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            cov_mat = torch.diag_embed(std_values)\n",
    "            batch_size = cov_mat.shape[0]\n",
    "            for i in range(batch_size):\n",
    "                cov_mat[i] += 1e-6 * torch.eye(cov_mat.size(1))  # Add a small constant to the diagonal\n",
    "            # print('cov_mat', cov_mat)\n",
    "            dist = MultivariateNormal(action_values, cov_mat)\n",
    "\n",
    "        return_tensors = True\n",
    "        if action is None:\n",
    "            action = dist.sample()\n",
    "            return_tensors = False\n",
    "        elif self.accelerator is None:\n",
    "            action = action.to(self.device)\n",
    "        else:\n",
    "            action = action.to(self.accelerator.device)\n",
    "\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "\n",
    "        if return_tensors:\n",
    "            return (\n",
    "                (\n",
    "                    self.scale_to_action_space(action, convert_to_torch=True)\n",
    "                    if not self.discrete_actions\n",
    "                    else action\n",
    "                ),\n",
    "                action_logprob,\n",
    "                dist_entropy,\n",
    "                state_values,\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                (\n",
    "                    self.scale_to_action_space(action.cpu().data.numpy())\n",
    "                    if not self.discrete_actions\n",
    "                    else action.cpu().data.numpy()\n",
    "                ),\n",
    "                action_logprob.cpu().data.numpy(),\n",
    "                dist_entropy.cpu().data.numpy(),\n",
    "                state_values.cpu().data.numpy(),\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iVdf_R4uDpqc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Population of SigmaPPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FYerQ_Z3585P"
   },
   "outputs": [],
   "source": [
    "\n",
    "def custom_create_population(\n",
    "        algo,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        one_hot,\n",
    "        net_config,\n",
    "        INIT_HP,\n",
    "        actor_network=None,\n",
    "        critic_network=None,\n",
    "        population_size=1,\n",
    "        num_envs=1,\n",
    "        device=\"cpu\",\n",
    "        accelerator=None,\n",
    "        torch_compiler=None,\n",
    "    ):\n",
    "        if \"PPO\" not in algo:\n",
    "            raise NotImplementedError(\"Only PPO for now\")\n",
    "\n",
    "        population = []\n",
    "\n",
    "        for idx in range(population_size):\n",
    "            agent = SigmaPPO(\n",
    "                state_dim=state_dim,\n",
    "                action_dim=action_dim,\n",
    "                one_hot=one_hot,\n",
    "                discrete_actions=False,\n",
    "                index=idx,\n",
    "                net_config=net_config,\n",
    "                batch_size=INIT_HP[\"BATCH_SIZE\"],\n",
    "                lr=INIT_HP[\"LR\"],\n",
    "                learn_step=INIT_HP[\"LEARN_STEP\"],\n",
    "                gamma=INIT_HP[\"GAMMA\"],\n",
    "                gae_lambda=INIT_HP[\"GAE_LAMBDA\"],\n",
    "                action_std_init=INIT_HP[\"ACTION_STD_INIT\"],\n",
    "                clip_coef=INIT_HP[\"CLIP_COEF\"],\n",
    "                ent_coef=INIT_HP[\"ENT_COEF\"],\n",
    "                vf_coef=INIT_HP[\"VF_COEF\"],\n",
    "                max_grad_norm=INIT_HP[\"MAX_GRAD_NORM\"],\n",
    "                target_kl=INIT_HP[\"TARGET_KL\"],\n",
    "                update_epochs=INIT_HP[\"UPDATE_EPOCHS\"],\n",
    "                actor_network=actor_network,\n",
    "                critic_network=critic_network,\n",
    "                device=device,\n",
    "                accelerator=accelerator,\n",
    "            )\n",
    "            population.append(agent)\n",
    "\n",
    "        return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PzGZqT7u6unA"
   },
   "outputs": [],
   "source": [
    "pop = custom_create_population(algo=\"SigmaPPO\",  # Algorithm\n",
    "                        state_dim=state_dim,  # State dimension\n",
    "                        action_dim=action_dim,  # Action dimension\n",
    "                        one_hot=one_hot,  # One-hot encoding\n",
    "                        net_config=None,  # Network configuration set as None\n",
    "                        actor_network=evolvable_actor, # Custom evolvable actor\n",
    "                        critic_network=[evolvable_critic, evolvable_vol_net], # Custom evolvable critic\n",
    "                        INIT_HP=INIT_HP,  # Initial hyperparameters\n",
    "                        population_size=INIT_HP[\"POP_SIZE\"],  # Population size\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa6QfVNX7Qgw",
    "outputId": "a7cd8ce0-dfde-4c03-9d39-2070f82631da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MakeEvolvable(\n",
      "  (feature_net): Sequential(\n",
      "    (feature_linear_layer_0): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (feature_activation_0): ReLU()\n",
      "    (feature_linear_layer_output): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (feature_activation_output): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for agent in pop:\n",
    "    print(agent.vol_net)\n",
    "    state, info = env.reset()\n",
    "    agent.get_action(state)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Km_iPMjnZBTP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jIfiBQVYumnz",
    "outputId": "3628848f-df80-4ca2-934f-f8ba63cb684a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 9954/200000 [03:37<1:03:57, 49.52step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Global steps 60672 ---\n",
      "Steps [10112, 10112, 10112, 10112, 10112, 10112]\n",
      "Scores: [-1243.6453003181653, -1555.3733385481316, -1507.773033485779, -1496.7876791630763, -1388.7472103345315, -1339.5358883137058]\n",
      "Fitnesses: ['-1452.71', '-1281.13', '-1388.72', '-1450.54', '-1380.77', '-1456.92']\n",
      "5 fitness avgs: ['-1452.71', '-1281.13', '-1388.72', '-1450.54', '-1380.77', '-1456.92']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 4&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">101</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/agilerl/hpo/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tournament.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">51</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">select</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">:param population: Population of agents</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">:type population: list[object]</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>51 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>elite, rank, max_id = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._elitism(population)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>new_population = []                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.elitism:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># keep top agent in population</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/agilerl/hpo/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tournament.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_elitism</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>max_id = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">max</span>([ind.index <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> ind <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> population])                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = population[np.argsort(rank)[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]]                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>42 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>elite = model.clone()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> elite, rank, max_id                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">select</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, population):                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/agilerl/algorithms/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ppo.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">704</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clone</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">701 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>{<span style=\"color: #808000; text-decoration-color: #808000\">\"params\"</span>: critic.parameters(), <span style=\"color: #808000; text-decoration-color: #808000\">\"lr\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lr},                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">702 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>]                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">703 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>704 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>optimizer.load_state_dict(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.state_dict())                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">705 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">706 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">707 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> wrap:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_compile.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">32</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inner</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>disable_fn = torch._dynamo.disable(fn, recursive)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>fn.__dynamo_disable = disable_fn                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>32 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> disable_fn(*args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/_dynamo/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">eval_frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">632</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_fn</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 629 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_fn</span>(*args, **kwargs):                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>prior = _maybe_set_eval_frame(callback)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 632 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 633 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>_maybe_set_eval_frame(prior)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">853</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_state_dict</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 850 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>saved_groups = deepcopy(state_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"param_groups\"</span>])                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 851 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 852 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(groups) != <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(saved_groups):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 853 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 854 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"loaded state dict has a different number of \"</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"parameter groups\"</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 855 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 856 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>param_lens = (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(g[<span style=\"color: #808000; text-decoration-color: #808000\">\"params\"</span>]) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> g <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> groups)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>loaded state dict has a different number of parameter groups\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 4>\u001b[0m:\u001b[94m101\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/agilerl/hpo/\u001b[0m\u001b[1;33mtournament.py\u001b[0m:\u001b[94m51\u001b[0m in \u001b[92mselect\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m:param population: Population of agents\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m:type population: list[object]\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m51 \u001b[2m│   │   \u001b[0melite, rank, max_id = \u001b[96mself\u001b[0m._elitism(population)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   │   \u001b[0mnew_population = []                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.elitism:  \u001b[2m# keep top agent in population\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/agilerl/hpo/\u001b[0m\u001b[1;33mtournament.py\u001b[0m:\u001b[94m42\u001b[0m in \u001b[92m_elitism\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m│   │   \u001b[0mmax_id = \u001b[96mmax\u001b[0m([ind.index \u001b[94mfor\u001b[0m ind \u001b[95min\u001b[0m population])                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m41 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = population[np.argsort(rank)[-\u001b[94m1\u001b[0m]]                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m42 \u001b[2m│   │   \u001b[0melite = model.clone()                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m elite, rank, max_id                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mselect\u001b[0m(\u001b[96mself\u001b[0m, population):                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/agilerl/algorithms/\u001b[0m\u001b[1;33mppo.py\u001b[0m:\u001b[94m704\u001b[0m in \u001b[92mclone\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m701 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m{\u001b[33m\"\u001b[0m\u001b[33mparams\u001b[0m\u001b[33m\"\u001b[0m: critic.parameters(), \u001b[33m\"\u001b[0m\u001b[33mlr\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m.lr},                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m702 \u001b[0m\u001b[2m│   │   │   \u001b[0m]                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m703 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m704 \u001b[2m│   │   \u001b[0moptimizer.load_state_dict(\u001b[96mself\u001b[0m.optimizer.state_dict())                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m705 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m706 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.accelerator \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m707 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m wrap:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_compile.py\u001b[0m:\u001b[94m32\u001b[0m in \u001b[92minner\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdisable_fn = torch._dynamo.disable(fn, recursive)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfn.__dynamo_disable = disable_fn                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m32 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m disable_fn(*args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/\u001b[0m\u001b[1;33meval_frame.py\u001b[0m:\u001b[94m632\u001b[0m in \u001b[92m_fn\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 629 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_fn\u001b[0m(*args, **kwargs):                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 630 \u001b[0m\u001b[2m│   │   │   \u001b[0mprior = _maybe_set_eval_frame(callback)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 632 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 633 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 634 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m_maybe_set_eval_frame(prior)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 635 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m853\u001b[0m in \u001b[92mload_state_dict\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 850 \u001b[0m\u001b[2m│   │   \u001b[0msaved_groups = deepcopy(state_dict[\u001b[33m\"\u001b[0m\u001b[33mparam_groups\u001b[0m\u001b[33m\"\u001b[0m])                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 851 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 852 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(groups) != \u001b[96mlen\u001b[0m(saved_groups):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 853 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 854 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mloaded state dict has a different number of \u001b[0m\u001b[33m\"\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mparameter groups\u001b[0m\u001b[33m\"\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 855 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 856 \u001b[0m\u001b[2m│   │   \u001b[0mparam_lens = (\u001b[96mlen\u001b[0m(g[\u001b[33m\"\u001b[0m\u001b[33mparams\u001b[0m\u001b[33m\"\u001b[0m]) \u001b[94mfor\u001b[0m g \u001b[95min\u001b[0m groups)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mloaded state dict has a different number of parameter groups\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TRAINING LOOP\n",
    "print(\"Training...\")\n",
    "pbar = trange(max_steps, unit=\"step\")\n",
    "while np.less([agent.steps[-1] for agent in pop], max_steps).all():\n",
    "    pop_episode_scores = []\n",
    "    for agent in pop:  # Loop through population\n",
    "        state, info = env.reset()  # Reset environment at start of episode\n",
    "        scores = np.zeros(num_envs)\n",
    "        completed_episode_scores = []\n",
    "        steps = 0\n",
    "\n",
    "        for _ in range(-(evo_steps // -agent.learn_step)):\n",
    "\n",
    "            states = []\n",
    "            actions = []\n",
    "            log_probs = []\n",
    "            rewards = []\n",
    "            dones = []\n",
    "            values = []\n",
    "\n",
    "            learn_steps = 0\n",
    "\n",
    "            for idx_step in range(-(agent.learn_step // -num_envs)):\n",
    "                if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "                    state = np.moveaxis(state, [-1], [-3])\n",
    "\n",
    "                # Get next action from agent\n",
    "                action, log_prob, _, value = agent.get_action(state)\n",
    "\n",
    "                # Act in environment\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "                total_steps += num_envs\n",
    "                steps += num_envs\n",
    "                learn_steps += num_envs\n",
    "\n",
    "                states.append(state)\n",
    "                actions.append(action)\n",
    "                log_probs.append(log_prob)\n",
    "                rewards.append(reward)\n",
    "                dones.append(terminated)\n",
    "                values.append(value)\n",
    "\n",
    "                state = next_state\n",
    "                scores += np.array(reward)\n",
    "\n",
    "                for idx, (d, t) in enumerate(zip(terminated, truncated)):\n",
    "                    if d or t:\n",
    "                        completed_episode_scores.append(scores[idx])\n",
    "                        agent.scores.append(scores[idx])\n",
    "                        scores[idx] = 0\n",
    "\n",
    "            pbar.update(learn_steps // len(pop))\n",
    "\n",
    "            if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "                next_state = np.moveaxis(next_state, [-1], [-3])\n",
    "\n",
    "            experiences = (\n",
    "                states,\n",
    "                actions,\n",
    "                log_probs,\n",
    "                rewards,\n",
    "                dones,\n",
    "                values,\n",
    "                next_state,\n",
    "            )\n",
    "            # Learn according to agent's RL algorithm\n",
    "            agent.learn(experiences)\n",
    "\n",
    "        agent.steps[-1] += steps\n",
    "        pop_episode_scores.append(completed_episode_scores)\n",
    "\n",
    "    # Evaluate population\n",
    "    fitnesses = [\n",
    "        agent.test(\n",
    "            env,\n",
    "            swap_channels=INIT_HP[\"CHANNELS_LAST\"],\n",
    "            max_steps=eval_steps,\n",
    "            loop=eval_loop,\n",
    "        )\n",
    "        for agent in pop\n",
    "    ]\n",
    "    mean_scores = [\n",
    "        (\n",
    "            np.mean(episode_scores)\n",
    "            if len(episode_scores) > 0\n",
    "            else \"0 completed episodes\"\n",
    "        )\n",
    "        for episode_scores in pop_episode_scores\n",
    "    ]\n",
    "\n",
    "    print(f\"--- Global steps {total_steps} ---\")\n",
    "    print(f\"Steps {[agent.steps[-1] for agent in pop]}\")\n",
    "    print(f\"Scores: {mean_scores}\")\n",
    "    print(f'Fitnesses: {[\"%.2f\"%fitness for fitness in fitnesses]}')\n",
    "    print(\n",
    "        f'5 fitness avgs: {[\"%.2f\"%np.mean(agent.fitness[-5:]) for agent in pop]}'\n",
    "    )\n",
    "\n",
    "    # Tournament selection and population mutation\n",
    "    elite, pop = tournament.select(pop)\n",
    "    pop = mutations.mutation(pop)\n",
    "\n",
    "    # Update step counter\n",
    "    for agent in pop:\n",
    "        agent.steps.append(agent.steps[-1])\n",
    "\n",
    "pbar.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGw1neTzzvnu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-xRqmdozv7r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R01Gg08jzwXA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHAOfj51zxFk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OQbZCaKzxae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwlkEgUlzx69"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d721af09cbfd4397a8cb0cd492e2dbcf",
      "81df709cb4564a72980cbcba5a7748d5",
      "e75dfa4a064d489798a492a2c7fda40d",
      "7e41ad5e339c4641ab6fe6b67e156dc3",
      "06d5a00e3f754d968a3f0a6f957c3177",
      "69597cefe3f2480c8e641eda329e6b6c",
      "0454364c289f4bd3ab2487d91c93f814",
      "4510cbf8c9b24f9ab8e3bc2c15f31505"
     ]
    },
    "id": "pWf3MikKt-oW",
    "outputId": "61441c3d-2fe2-4478-add2-39b054e99c65"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241031_132145-sj6rtb6s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/freedomriverdanccer/AgileRL/runs/sj6rtb6s' target=\"_blank\">LunarLander-v2-EvoHPO-PPO-10312024132138</a></strong> to <a href='https://wandb.ai/freedomriverdanccer/AgileRL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/freedomriverdanccer/AgileRL' target=\"_blank\">https://wandb.ai/freedomriverdanccer/AgileRL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/freedomriverdanccer/AgileRL/runs/sj6rtb6s' target=\"_blank\">https://wandb.ai/freedomriverdanccer/AgileRL/runs/sj6rtb6s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|4         | 9975/200000 [  02:03<31:55:58,  1.65step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 60672 ---\n",
      "                Fitness:\t\t['-48.77', '-101.89', '-221.74', '-271.12', '-53.30', '-107.97']\n",
      "                Score:\t\t[-176.23922055595082, -155.75562717239725, -170.69177859329497, -177.7026453190563, -150.02117360401311, -141.84729437692192]\n",
      "                5 fitness avgs:\t['-48.77', '-53.30', '-48.77', '-48.77', '-221.74', '-221.74']\n",
      "                10 score avgs:\t['-173.84', '-101.44', '-173.84', '-173.84', '-184.69', '-184.69']\n",
      "                Agents:\t\t[0, 6, 7, 8, 9, 10]\n",
      "                Steps:\t\t[10112, 10112, 10112, 10112, 10112, 10112]\n",
      "                Mutations:\t\t['None', 'arch', 'None', 'None', 'None', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|9         | 19929/200000 [  03:54<38:13:48,  1.31step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 121344 ---\n",
      "                Fitness:\t\t['-86.23', '-122.45', '-265.49', '-120.54', '-102.91', '-167.36']\n",
      "                Score:\t\t[-141.97666576566547, -140.5941714317149, -136.11190112576617, -103.09168031440569, -109.01930863991645, -147.17937029822264]\n",
      "                5 fitness avgs:\t['-67.50', '-67.50', '-162.32', '-157.13', '-162.32', '-84.65']\n",
      "                10 score avgs:\t['-158.96', '-158.96', '-48.81', '-161.82', '-48.81', '-146.81']\n",
      "                Agents:\t\t[0, 11, 12, 13, 14, 15]\n",
      "                Steps:\t\t[20224, 20224, 20224, 20224, 20224, 20224]\n",
      "                Mutations:\t\t['lr', 'param', 'None', 'None', 'None', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|#4        | 29883/200000 [  06:00<41:38:16,  1.13step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 182016 ---\n",
      "                Fitness:\t\t['-22.68', '-166.74', '-15.47', '-231.88', '-66.99', '-138.34']\n",
      "                Score:\t\t[-128.88283848932244, -80.64383562592732, -108.82206316567299, -215.3515963769123, -133.86973578170796, -77.7678894780903]\n",
      "                5 fitness avgs:\t['-113.37', '-113.37', '-113.37', '-130.55', '-113.37', '-52.56']\n",
      "                10 score avgs:\t['-120.29', '-120.29', '-120.29', '-106.53', '-120.29', '-96.86']\n",
      "                Agents:\t\t[12, 16, 17, 18, 19, 20]\n",
      "                Steps:\t\t[30336, 30336, 30336, 30336, 30336, 30336]\n",
      "                Mutations:\t\t['arch', 'param', 'None', 'param', 'param', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|#9        | 39837/200000 [  07:55<21:28:28,  2.07step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 242688 ---\n",
      "                Fitness:\t\t['4.29', '16.51', '82.47', '-152.01', '44.58', '-88.86']\n",
      "                Score:\t\t[-72.76982630581337, -57.184796246310185, -69.05850945749296, -123.83158000776433, -87.83964405370523, -60.962476671962065]\n",
      "                5 fitness avgs:\t['-64.41', '-64.41', '-61.63', '-80.90', '-64.41', '-64.41']\n",
      "                10 score avgs:\t['-74.54', '-74.54', '-63.47', '-39.71', '-74.54', '-74.54']\n",
      "                Agents:\t\t[17, 21, 22, 23, 24, 25]\n",
      "                Steps:\t\t[40448, 40448, 40448, 40448, 40448, 40448]\n",
      "                Mutations:\t\t['arch', 'None', 'None', 'None', 'None', 'lr']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|##4       | 49791/200000 [  10:01<23:20:46,  1.79step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 303360 ---\n",
      "                Fitness:\t\t['29.64', '61.96', '-18.47', '66.85', '36.93', '-29.34']\n",
      "                Score:\t\t['0 completed episodes', -83.06512454319315, -57.54712295723905, 5.477688339793149, -11.707507770864643, 20.49466635440831]\n",
      "                5 fitness avgs:\t['-51.35', '-39.14', '-51.35', '-51.35', '-45.60', '-39.14']\n",
      "                10 score avgs:\t['28.65', '-52.42', '28.65', '28.65', '-74.54', '-52.42']\n",
      "                Agents:\t\t[23, 26, 27, 28, 29, 30]\n",
      "                Steps:\t\t[50560, 50560, 50560, 50560, 50560, 50560]\n",
      "                Mutations:\t\t['None', 'None', 'bs', 'None', 'bs', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|##9       | 59745/200000 [  12:07<31:31:35,  1.24step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 364032 ---\n",
      "                Fitness:\t\t['156.71', '-5.36', '32.20', '-58.64', '-48.40', '63.58']\n",
      "                Score:\t\t[-48.297843928705305, 152.63450061304798, -34.48455497363226, '0 completed episodes', -100.00753211582501, 52.239736687181704]\n",
      "                5 fitness avgs:\t['24.34', '24.34', '4.14', '24.34', '4.14', '17.93']\n",
      "                10 score avgs:\t['-10.65', '-10.65', '-35.89', '-10.65', '-35.89', '-40.74']\n",
      "                Agents:\t\t[23, 31, 32, 33, 34, 35]\n",
      "                Steps:\t\t[60672, 60672, 60672, 60672, 60672, 60672]\n",
      "                Mutations:\t\t['arch', 'None', 'None', 'None', 'None', 'param']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|###4      | 69699/200000 [  14:08<32:00:40,  1.13step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 424704 ---\n",
      "                Fitness:\t\t['-131.08', '-82.06', '-113.25', '-42.78', '-55.96', '-31.20']\n",
      "                Score:\t\t[-141.02258322140182, '0 completed episodes', '0 completed episodes', 26.175770216717346, -77.31401164717573, -94.97396464715598]\n",
      "                5 fitness avgs:\t['32.27', '32.27', '36.36', '28.51', '32.27', '32.27']\n",
      "                10 score avgs:\t['-45.22', '-45.22', '7.73', '-10.65', '-45.22', '-45.22']\n",
      "                Agents:\t\t[35, 36, 37, 38, 39, 40]\n",
      "                Steps:\t\t[70784, 70784, 70784, 70784, 70784, 70784]\n",
      "                Mutations:\t\t['arch', 'None', 'None', 'param', 'None', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|###9      | 79653/200000 [  16:08<27:45:25,  1.20step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 485376 ---\n",
      "                Fitness:\t\t['-93.20', '-70.47', '-142.07', '-157.16', '-47.05', '17.44']\n",
      "                Score:\t\t[-88.25023465417148, -97.57860022799575, -71.3074533580399, -107.21928275432323, -57.24363410105409, -81.93577449494707]\n",
      "                5 fitness avgs:\t['38.85', '38.85', '21.27', '38.85', '21.27', '25.95']\n",
      "                10 score avgs:\t['-74.24', '-74.24', '-99.51', '-74.24', '-99.51', '-46.65']\n",
      "                Agents:\t\t[40, 41, 42, 43, 44, 45]\n",
      "                Steps:\t\t[80896, 80896, 80896, 80896, 80896, 80896]\n",
      "                Mutations:\t\t['arch', 'param', 'lr', 'lr', 'None', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|####4     | 89607/200000 [  18:07<27:09:10,  1.13step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 546048 ---\n",
      "                Fitness:\t\t['-67.54', '-51.07', '-71.25', '-83.75', '-144.27', '-40.82']\n",
      "                Score:\t\t[-92.54870476187605, -83.09168859413971, -117.26894048102199, -69.45736984938493, -115.59761381897825, -99.19487029624085]\n",
      "                5 fitness avgs:\t['1.30', '1.30', '12.14', '5.61', '-9.47', '12.14']\n",
      "                10 score avgs:\t['-103.84', '-103.84', '-72.45', '-46.62', '-125.35', '-72.45']\n",
      "                Agents:\t\t[45, 46, 47, 48, 49, 50]\n",
      "                Steps:\t\t[91008, 91008, 91008, 91008, 91008, 91008]\n",
      "                Mutations:\t\t['lr', 'param', 'arch', 'None', 'param', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|####9     | 99561/200000 [  20:13<24:05:44,  1.16step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 606720 ---\n",
      "                Fitness:\t\t['-96.48', '-65.29', '-139.11', '-19.42', '-38.49', '-108.90']\n",
      "                Score:\t\t[-74.14464925564207, -92.40042057585039, -86.12892448037017, -82.34105152346754, -114.89749455277043, -88.7301991013866]\n",
      "                5 fitness avgs:\t['-10.67', '-10.67', '-10.67', '-10.67', '-10.67', '-30.39']\n",
      "                10 score avgs:\t['-60.90', '-60.90', '-60.90', '-60.90', '-60.90', '-54.50']\n",
      "                Agents:\t\t[48, 51, 52, 53, 54, 55]\n",
      "                Steps:\t\t[101120, 101120, 101120, 101120, 101120, 101120]\n",
      "                Mutations:\t\t['None', 'arch', 'arch', 'None', 'None', 'arch']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|#####4    | 109515/200000 [  21:59<18:06:31,  1.39step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 667392 ---\n",
      "                Fitness:\t\t['-26.62', '-129.02', '-116.78', '-43.23', '-52.59', '-81.52']\n",
      "                Score:\t\t[-87.79195366292578, -82.76861279905067, -89.82692392858988, -81.3693802368153, -104.06089211134508, -104.75442039041761]\n",
      "                5 fitness avgs:\t['-28.71', '-28.71', '-28.71', '-59.41', '-32.03', '-33.90']\n",
      "                10 score avgs:\t['-94.38', '-94.38', '-94.38', '-109.45', '-76.83', '-118.17']\n",
      "                Agents:\t\t[48, 56, 57, 58, 59, 60]\n",
      "                Steps:\t\t[111232, 111232, 111232, 111232, 111232, 111232]\n",
      "                Mutations:\t\t['None', 'None', 'None', 'None', 'param', 'lr']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|#####9    | 119469/200000 [  23:54<16:52:43,  1.33step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 728064 ---\n",
      "                Fitness:\t\t['-107.22', '-122.53', '-70.48', '-97.26', '-139.52', '-113.37']\n",
      "                Score:\t\t[-97.03724675199348, -90.94350791484624, -100.73155590224533, -97.49177504347637, -104.50244626598483, -94.74597996485201]\n",
      "                5 fitness avgs:\t['-36.57', '-72.62', '-46.98', '-36.57', '-46.98', '-43.92']\n",
      "                10 score avgs:\t['-114.34', '-95.58', '-87.41', '-114.34', '-87.41', '-102.19']\n",
      "                Agents:\t\t[57, 61, 62, 63, 64, 65]\n",
      "                Steps:\t\t[121344, 121344, 121344, 121344, 121344, 121344]\n",
      "                Mutations:\t\t['param', 'None', 'None', 'None', 'None', 'param']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|######4   | 129423/200000 [  25:45<15:25:15,  1.27step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 788736 ---\n",
      "                Fitness:\t\t['-61.52', '-80.04', '-108.44', '-75.89', '-52.23', '-110.31']\n",
      "                Score:\t\t[-105.76898978118282, -103.55824822308122, -111.13394707135542, -126.12025056059439, -110.67323653469296, -100.81077999164954]\n",
      "                5 fitness avgs:\t['-60.91', '-60.91', '-60.91', '-52.36', '-52.36', '-60.91']\n",
      "                10 score avgs:\t['-109.87', '-109.87', '-109.87', '-113.57', '-113.57', '-109.87']\n",
      "                Agents:\t\t[64, 66, 67, 68, 69, 70]\n",
      "                Steps:\t\t[131456, 131456, 131456, 131456, 131456, 131456]\n",
      "                Mutations:\t\t['bs', 'arch', 'arch', 'arch', 'param', 'lr']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|######9   | 139377/200000 [  27:44<14:16:51,  1.18step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 849408 ---\n",
      "                Fitness:\t\t['-117.73', '-54.99', '-90.13', '-69.13', '-106.27', '-86.08']\n",
      "                Score:\t\t[-99.72556868278174, -114.89462332511049, -104.11453362907882, -103.15080000801638, -92.02041686700224, -94.89752364088878]\n",
      "                5 fitness avgs:\t['-55.16', '-61.38', '-61.38', '-55.16', '-49.43', '-67.71']\n",
      "                10 score avgs:\t['-111.71', '-99.95', '-99.95', '-111.71', '-103.78', '-107.10']\n",
      "                Agents:\t\t[66, 71, 72, 73, 74, 75]\n",
      "                Steps:\t\t[141568, 141568, 141568, 141568, 141568, 141568]\n",
      "                Mutations:\t\t['arch', 'None', 'None', 'arch', 'None', 'arch']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|#######4  | 149331/200000 [  29:30<9:39:42,  1.46step/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 910080 ---\n",
      "                Fitness:\t\t['-137.86', '-57.56', '-43.97', '-102.76', '-82.33', '-105.38']\n",
      "                Score:\t\t[-116.23200768557322, -99.67399672589278, -98.35852634132415, -99.39424578817624, -83.89605974888391, -100.09812341202554]\n",
      "                5 fitness avgs:\t['-66.29', '-66.29', '-69.01', '-66.29', '-69.01', '-69.01']\n",
      "                10 score avgs:\t['-85.88', '-85.88', '-100.77', '-85.88', '-100.77', '-100.77']\n",
      "                Agents:\t\t[72, 76, 77, 78, 79, 80]\n",
      "                Steps:\t\t[151680, 151680, 151680, 151680, 151680, 151680]\n",
      "                Mutations:\t\t['param', 'param', 'arch', 'None', 'param', 'lr']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|#######9  | 159285/200000 [  31:17<8:39:31,  1.31step/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 970752 ---\n",
      "                Fitness:\t\t['-36.86', '-52.54', '-145.31', '-73.44', '-22.79', '-91.80']\n",
      "                Score:\t\t[-98.76523084071081, -51.27714049258225, -149.54934579919768, -94.16636710447274, -68.46088076628932, -65.87190853059533]\n",
      "                5 fitness avgs:\t['-68.24', '-68.33', '-71.47', '-68.33', '-68.24', '-68.24']\n",
      "                10 score avgs:\t['-43.85', '-112.83', '-38.84', '-112.83', '-43.85', '-43.85']\n",
      "                Agents:\t\t[79, 81, 82, 83, 84, 85]\n",
      "                Steps:\t\t[161792, 161792, 161792, 161792, 161792, 161792]\n",
      "                Mutations:\t\t['param', 'arch', 'None', 'param', 'None', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|########4 | 169239/200000 [  33:12<3:50:55,  2.22step/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 1031424 ---\n",
      "                Fitness:\t\t['2.36', '-146.93', '-70.97', '-38.51', '-93.83', '-91.97']\n",
      "                Score:\t\t[-63.35056974193875, -122.79288938239314, -50.13711297656004, -53.38054260923758, -91.08038090166053, -61.11030378091783]\n",
      "                5 fitness avgs:\t['-43.26', '-51.53', '-51.53', '-61.16', '-51.53', '-61.16']\n",
      "                10 score avgs:\t['-68.45', '-22.18', '-22.18', '-28.47', '-22.18', '-28.47']\n",
      "                Agents:\t\t[79, 86, 87, 88, 89, 90]\n",
      "                Steps:\t\t[171904, 171904, 171904, 171904, 171904, 171904]\n",
      "                Mutations:\t\t['param', 'None', 'bs', 'None', 'param', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|########9 | 179193/200000 [  35:03<4:26:48,  1.30step/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 1092096 ---\n",
      "                Fitness:\t\t['-1.69', '-67.20', '-26.65', '-104.65', '-119.55', '17.78']\n",
      "                Score:\t\t[-28.744827500340183, -81.33719910546594, -71.65083239862695, -97.06579737346472, -122.42425156069758, -71.17673045598136]\n",
      "                5 fitness avgs:\t['-47.15', '-47.15', '-46.41', '-54.52', '-54.52', '-47.15']\n",
      "                10 score avgs:\t['-52.27', '-52.27', '-65.06', '-95.58', '-95.58', '-52.27']\n",
      "                Agents:\t\t[90, 91, 92, 93, 94, 95]\n",
      "                Steps:\t\t[182016, 182016, 182016, 182016, 182016, 182016]\n",
      "                Mutations:\t\t['param', 'arch', 'param', 'None', 'arch', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|#########4| 189147/200000 [  37:04<2:42:47,  1.11step/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 1152768 ---\n",
      "                Fitness:\t\t['-37.63', '-166.77', '-60.11', '-75.89', '-110.12', '5.74']\n",
      "                Score:\t\t[-34.022859262901896, -131.45391749016397, -61.97133241476612, -108.11194094444645, -80.71938323373868, -56.98650555624211]\n",
      "                5 fitness avgs:\t['-28.79', '-37.47', '-28.79', '-28.79', '-52.49', '-41.22']\n",
      "                10 score avgs:\t['-49.22', '-42.36', '-49.22', '-49.22', '-122.45', '-24.18']\n",
      "                Agents:\t\t[95, 96, 97, 98, 99, 100]\n",
      "                Steps:\t\t[192128, 192128, 192128, 192128, 192128, 192128]\n",
      "                Mutations:\t\t['arch', 'None', 'arch', 'arch', 'None', 'None']\n",
      "                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#########9| 199080/200000 [  38:20<  00:04, 184.10step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                --- Global Steps 1213440 ---\n",
      "                Fitness:\t\t['-67.83', '-42.92', '-104.14', '-22.30', '-103.30', '-59.10']\n",
      "                Score:\t\t[-37.1213742741476, -86.57895201494533, -64.83913583892107, -25.01514108695892, -101.08372238821408, -48.12941662413789]\n",
      "                5 fitness avgs:\t['-24.46', '-24.46', '-33.56', '-64.35', '-33.56', '-44.24']\n",
      "                10 score avgs:\t['50.49', '50.49', '8.14', '-113.30', '8.14', '-31.23']\n",
      "                Agents:\t\t[98, 101, 102, 103, 104, 105]\n",
      "                Steps:\t\t[202240, 202240, 202240, 202240, 202240, 202240]\n",
      "                Mutations:\t\t['None', 'bs', 'None', 'None', 'None', 'lr']\n",
      "                \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d721af09cbfd4397a8cb0cd492e2dbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/best_fitness</td><td>▂▁▃▆▅█▃▄▂▃▃▁▂▂▂▃▄▄▄▃</td></tr><tr><td>eval/mean_fitness</td><td>▁▁▃▆██▄▄▄▄▄▂▄▃▃▄▄▅▄▄</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train/agent_0_loss</td><td>█▃▂▁▁▁▄▃▃▂▂▁▁▃▁▂▂▁▂▃</td></tr><tr><td>train/agent_1_loss</td><td>█▅█▂▂▃▁▁▇▂▂▂▄▂▂▄▂▁▃▃</td></tr><tr><td>train/agent_2_loss</td><td>█▂▃▁▂▂▁▂▁▂▁▂▁▃▂▁▁▃▆▂</td></tr><tr><td>train/agent_3_loss</td><td>▆█▅▄▁▁▁▂▅▃▂▁▂▂▂▂▄▁▂▃</td></tr><tr><td>train/agent_4_loss</td><td>█▅▆▃▁▃▁▂▁▂▃▃▂▂▁▃▁▃▁▂</td></tr><tr><td>train/agent_5_loss</td><td>▅▄▃▂▁▄▂▃▃▃▂▃▁▂▃▃▃▂▄█</td></tr><tr><td>train/mean_score</td><td>▁▂▃▅▇█▅▄▄▄▄▄▃▄▄▄▅▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/best_fitness</td><td>-22.29863</td></tr><tr><td>eval/mean_fitness</td><td>-66.5977</td></tr><tr><td>global_step</td><td>1213440</td></tr><tr><td>train/agent_0_loss</td><td>0.16962</td></tr><tr><td>train/agent_1_loss</td><td>0.10075</td></tr><tr><td>train/agent_2_loss</td><td>0.1201</td></tr><tr><td>train/agent_3_loss</td><td>0.13996</td></tr><tr><td>train/agent_4_loss</td><td>0.0332</td></tr><tr><td>train/agent_5_loss</td><td>0.46607</td></tr><tr><td>train/mean_score</td><td>-60.46129</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LunarLander-v2-EvoHPO-PPO-10312024132138</strong> at: <a href='https://wandb.ai/freedomriverdanccer/AgileRL/runs/sj6rtb6s' target=\"_blank\">https://wandb.ai/freedomriverdanccer/AgileRL/runs/sj6rtb6s</a><br/> View project at: <a href='https://wandb.ai/freedomriverdanccer/AgileRL' target=\"_blank\">https://wandb.ai/freedomriverdanccer/AgileRL</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241031_132145-sj6rtb6s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py:2386: UserWarning: Run (sj6rtb6s) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "\r100%|#########9| 199080/200000 [  38:59<  00:10, 85.09step/s] \n"
     ]
    }
   ],
   "source": [
    "# from agilerl.training.train_on_policy import train_on_policy\n",
    "\n",
    "# trained_pop, pop_fitnesses = train_on_policy(\n",
    "#     env=env,                              # Gym-style environment\n",
    "#     env_name=\"LunarLander-v2\",  # Environment name\n",
    "#     algo=\"PPO\",  # Algorithm\n",
    "#     pop=pop,  # Population of agents\n",
    "#     swap_channels=INIT_HP['CHANNELS_LAST'],  # Swap image channel from last to first\n",
    "#     max_steps=200000,  # Max number of training steps\n",
    "#     evo_steps=10000,  # Evolution frequency\n",
    "#     eval_steps=None,  # Number of steps in evaluation episode\n",
    "#     eval_loop=1,  # Number of evaluation episodes\n",
    "#     target=200.,  # Target score for early stopping\n",
    "#     tournament=tournament,  # Tournament selection object\n",
    "#     mutation=mutations,  # Mutations object\n",
    "#     wb=INIT_HP['WANDB'],  # Weights and Biases tracking\n",
    "#     wandb_api_key=INIT_HP['wandb_api_key'],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfs2ubPVuEg-"
   },
   "outputs": [],
   "source": [
    "agent = trained_pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkFv32U56e-K",
    "outputId": "f473ad35-7b94-4119-c520-6eef6bda7e79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85239583,  1.19907   ,  1.0199465 ,  1.1254752 ,  2.9390442 ,\n",
       "         1.2153194 ,  0.7284626 ,  0.4107304 ],\n",
       "       [-1.0123198 , -0.08863777,  4.0035477 , -1.8826923 ,  0.6858207 ,\n",
       "        -0.0595629 ,  0.9837324 ,  0.4361292 ],\n",
       "       [-0.03299822, -1.384671  , -3.9240286 , -0.6785452 , -2.195526  ,\n",
       "         4.4582644 ,  0.03838794,  0.660428  ],\n",
       "       [-0.87020344,  1.2908074 ,  3.0512488 , -3.3140237 , -0.12082151,\n",
       "         4.762933  ,  0.26961353,  0.6631864 ],\n",
       "       [ 0.6808699 ,  0.7150591 ,  2.635245  , -3.7163386 ,  1.1280224 ,\n",
       "        -2.3501148 ,  0.53162354,  0.758555  ],\n",
       "       [ 0.18915331, -0.74293584,  2.6423454 ,  1.3652818 ,  0.46170154,\n",
       "        -0.42255315,  0.13336295,  0.57097054],\n",
       "       [-0.9718503 , -0.5298286 ,  3.7354355 ,  1.5907434 , -1.3374785 ,\n",
       "        -1.350843  ,  0.0289788 ,  0.9720034 ],\n",
       "       [-0.31048515,  0.2554536 , -0.04210167,  1.3130286 , -2.9176698 ,\n",
       "         1.969855  ,  0.26110598,  0.20814197],\n",
       "       [-1.1522628 ,  0.30782232, -3.940364  , -3.364575  , -2.8774426 ,\n",
       "        -0.6493589 ,  0.4329381 ,  0.56967413],\n",
       "       [-1.4057344 ,  1.1024963 ,  4.882044  , -4.129152  , -1.7651868 ,\n",
       "        -3.5295265 ,  0.9502247 ,  0.8905148 ],\n",
       "       [-0.16928342, -0.4882494 ,  1.4228302 ,  0.38561568, -0.5635257 ,\n",
       "         2.9409728 ,  0.01619353,  0.20242617],\n",
       "       [ 1.3982127 ,  1.2154677 , -4.9291234 ,  1.2090453 ,  1.124942  ,\n",
       "        -2.1661098 ,  0.21657978,  0.27114514],\n",
       "       [-1.276652  ,  1.2225578 , -1.5696472 , -3.4390535 ,  1.2428055 ,\n",
       "         4.7427034 ,  0.76084656,  0.50458276],\n",
       "       [-1.4297146 , -1.0319622 ,  2.6597545 , -0.02250576,  2.9521396 ,\n",
       "        -0.17935763,  0.3753979 ,  0.84439874],\n",
       "       [ 0.26503345, -0.06794076,  0.90924984, -2.4022965 ,  2.7118528 ,\n",
       "        -4.85616   ,  0.3413544 ,  0.339358  ],\n",
       "       [-0.20652789, -1.2393951 ,  1.3517697 ,  4.3117285 ,  2.0031962 ,\n",
       "         3.9077744 ,  0.37270567,  0.17508377]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXs-kgWL6noP",
    "outputId": "72b9a38c-c465-4f29-f8ca-1692c34a5656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 2, 1, 0, 1, 3, 2, 2, 0, 3, 3, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raGPm2Ce6WHT",
    "outputId": "25952fa5-014b-463a-8273-8009c2761a85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 1, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1, 3, 1, 1, 1]),\n",
       " array([-0.13260274, -0.00351821, -0.00383964, -0.6369603 , -0.04836098,\n",
       "        -0.00381565, -0.09055927, -0.04441704, -0.05331632, -0.17483655,\n",
       "        -0.07071134, -0.01006466, -0.00390373, -0.00330666, -0.008079  ,\n",
       "        -1.0205497 ], dtype=float32),\n",
       " array([0.37867695, 0.02484129, 0.02674724, 0.7026828 , 0.19157144,\n",
       "        0.02653088, 0.30269036, 0.18310887, 0.20520574, 0.4447777 ,\n",
       "        0.2560623 , 0.05715971, 0.02692572, 0.02410962, 0.04798388,\n",
       "        0.7158035 ], dtype=float32),\n",
       " array([-12.471022 ,   2.430461 , -39.258907 , -34.27118  , -44.87177  ,\n",
       "          8.222554 , -14.760967 , -45.669674 , -39.85141  , -42.973305 ,\n",
       "        -13.004054 , -22.519735 ,  -4.1115828, -33.528423 , -25.043116 ,\n",
       "        -36.668076 ], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_action(state=env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZIL9MGV6N0S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0454364c289f4bd3ab2487d91c93f814": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06d5a00e3f754d968a3f0a6f957c3177": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4510cbf8c9b24f9ab8e3bc2c15f31505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69597cefe3f2480c8e641eda329e6b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e41ad5e339c4641ab6fe6b67e156dc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81df709cb4564a72980cbcba5a7748d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06d5a00e3f754d968a3f0a6f957c3177",
      "placeholder": "​",
      "style": "IPY_MODEL_69597cefe3f2480c8e641eda329e6b6c",
      "value": "0.026 MB of 0.026 MB uploaded\r"
     }
    },
    "d721af09cbfd4397a8cb0cd492e2dbcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_81df709cb4564a72980cbcba5a7748d5",
       "IPY_MODEL_e75dfa4a064d489798a492a2c7fda40d"
      ],
      "layout": "IPY_MODEL_7e41ad5e339c4641ab6fe6b67e156dc3"
     }
    },
    "e75dfa4a064d489798a492a2c7fda40d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0454364c289f4bd3ab2487d91c93f814",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4510cbf8c9b24f9ab8e3bc2c15f31505",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
